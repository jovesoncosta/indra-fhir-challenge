üöÄ Desafio T√©cnico: Pipeline de Dados FHIR (Indra Group)
Este reposit√≥rio cont√©m a solu√ß√£o completa para o Desafio T√©cnico de Engenheiro de Dados (Especialista em HL7 FHIR), demonstrando um pipeline de dados ponta-a-ponta, desde a ingest√£o de dados legados (CSV) at√© a carga em um servidor FHIR R4, com enriquecimento sem√¢ntico (RNDS e SNOMED CT).

Status: üèÜ Conclu√≠do!

üéØ Objetivo do Projeto
O objetivo principal √© simular um cen√°rio real de interoperabilidade em sa√∫de, onde dados de pacientes de um sistema legado (arquivo patients.csv) precisam ser:

Extra√≠dos e limpos.

Transformados para o padr√£o internacional (FHIR R4).

Enriquecidos com padr√µes nacionais (RNDS - BRIndividuo) e terminologias cl√≠nicas (SNOMED CT).

Carregados (Load) de forma resiliente em um servidor FHIR.

üèõÔ∏è Arquitetura da Solu√ß√£o
A solu√ß√£o utiliza uma arquitetura moderna, containerizada e ass√≠ncrona, garantindo desacoplamento, resili√™ncia e escalabilidade.

``

O fluxo de dados √© o seguinte:

Orquestra√ß√£o (Airflow): A DAG indra_fhir_pipeline inicia o processo.

Extra√ß√£o (Python/Pandas): A primeira tarefa (ler_csv_enviar_kafka) l√™ o patients.csv, realiza um ETL (Extract, Transform, Load) inicial (limpando CPFs, datas, g√™neros) e produz uma mensagem JSON para cada paciente.

Mensageria (Kafka): As mensagens s√£o publicadas no t√≥pico patient_data. O Kafka atua como um buffer resiliente, garantindo que os dados n√£o sejam perdidos se o servidor FHIR estiver offline.

Carga (Python/FHIR): A segunda tarefa (ler_kafka_gravar_fhir) consome as mensagens do Kafka, realiza o Enriquecimento Sem√¢ntico (aplicando os perfis) e carrega os dados no HAPI FHIR Server via API REST.

üõ†Ô∏è Stack de Tecnologias
Containeriza√ß√£o: Docker e Docker Compose

Orquestra√ß√£o de Pipeline: Apache Airflow

Mensageria e Streaming: Apache Kafka

Servidor Cl√≠nico (CDR): HAPI FHIR (R4)

Linguagem de ETL e Scripts: Python (Pandas, kafka-python, requests)

Padr√µes de Interoperabilidade: HL7 FHIR R4, RNDS (BRIndividuo), SNOMED CT

üî¨ Destaques T√©cnicos e Enriquecimento Sem√¢ntico
Este pipeline vai al√©m de uma simples carga de dados, implementando dois n√≠veis de interoperabilidade avan√ßada que foram solicitados como b√¥nus.

1. Padr√£o RNDS (BRIndividuo)
O Resource Patient n√£o √© gen√©rico. Ele √© estruturado para seguir o perfil BRIndividuo da RNDS (Rede Nacional de Dados em Sa√∫de).

meta.profile: O JSON de cada paciente √© "carimbado" com a URL can√¥nica do perfil.

Identificador Oficial: O CPF n√£o √© salvo de forma gen√©rica, mas sim usando o OID oficial do Minist√©rio da Sa√∫de (http://www.saude.gov.br/fhir/rnds/StructureDefinition/cpf-usuario).

Nome Estruturado: O nome √© quebrado em family (sobrenome) e given (nomes pr√≥prios) para maior qualidade de dados.

JSON

"meta": {
  "profile": [
    "https://fhir.rnds.saude.gov.br/StructureDefinition/BRIndividuo-1.0"
  ]
}
2. Condi√ß√µes Cl√≠nicas com SNOMED CT
A coluna "Observa√ß√£o" (ex: "Diab√©tico", "Hipertenso") n√£o √© salva como texto livre.

Recurso Condition: Para cada condi√ß√£o cl√≠nica, um recurso Condition separado √© criado, permitindo que o hist√≥rico de sa√∫de do paciente seja estruturado.

Mapeamento Sem√¢ntico: Atrav√©s do dicion√°rio CONDICOES_MAP, o texto "sujo" (ex: "diabetico") √© traduzido para o c√≥digo universal SNOMED CT (ex: 44054006 - Diabetes mellitus).

Isso √© interoperabilidade sem√¢ntica: qualquer sistema no mundo que entenda SNOMED agora entende o dado deste paciente, mesmo sem entender portugu√™s.

``

üöÄ Como Executar o Projeto
Siga estes passos para subir toda a infraestrutura e executar o pipeline.

Pr√©-requisitos
Docker

Docker Compose

1. Garantindo uma Execu√ß√£o Limpa
Como o Kafka e o HAPI FHIR (em modo de desenvolvimento) persistem dados em volumes, √© crucial limpar o ambiente antes de um novo teste completo.

Bash

docker compose down -v
(O -v remove os volumes, limpando o banco do HAPI e os logs do Kafka).

2. Subindo a Infraestrutura
Com o Docker em execu√ß√£o, suba todos os servi√ßos em modo "detached" (-d):

Bash

docker compose up -d
(Aguarde cerca de 2 a 3 minutos para que o Kafka e o HAPI FHIR, que s√£o pesados, estejam totalmente prontos).

3. Acessando os Servi√ßos
HAPI FHIR Server: http://localhost:8080

Apache Airflow: http://localhost:8081 (Login: admin / Senha: admin)

4. Executando o Pipeline
Acesse o Airflow (http://localhost:8081).

Encontre a DAG indra_fhir_pipeline.

Despause a DAG (clicando no bot√£o "toggle" √† esquerda).

Clique no bot√£o "Play" (‚ñ∂Ô∏è) √† direita e selecione "Trigger DAG".

``

‚úÖ Como Validar o Sucesso
Ap√≥s a DAG ficar verde (Success) no Airflow, voc√™ pode validar os dados:

1. Valida√ß√£o do Paciente (BRIndividuo)
Acesse o endpoint de busca de Pacientes. Voc√™ ver√° os dados carregados e o "total" de pacientes.

URL: http://localhost:8080/fhir/Patient

``

2. Valida√ß√£o das Condi√ß√µes (SNOMED)
Acesse o endpoint de Condi√ß√µes para ver os dados de diabetes, hipertens√£o e gesta√ß√£o com os c√≥digos SNOMED.

URL: http://localhost:8080/fhir/Condition

``

3. Visualiza√ß√£o (Opcional)
Para uma visualiza√ß√£o mais amig√°vel, voc√™ pode usar um cliente FHIR como o Vanya Client e apont√°-lo para http://localhost:8080/fhir.

``